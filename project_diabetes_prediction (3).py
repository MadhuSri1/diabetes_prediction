# -*- coding: utf-8 -*-
"""Project - Diabetes Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n4wdk8npTaGGQ9Z2XkVOFyj1YCXpwk_-

**Importing** **the** **Dependencies**
"""

import numpy as np
  import pandas as pd
  import seaborn as sns
  import matplotlib.pyplot as plt
  import pickle
  from sklearn.preprocessing import StandardScaler
  from sklearn.model_selection import train_test_split
  from sklearn import svm
  from sklearn.metrics import accuracy_score

"""**Data** **Collection** **and** **Ananlysis**"""

# loading the diabetes dataset to a pandas DataFrame
diabetes_dataset = pd.read_csv('/content/diabetes.csv')

# printing the first 10 rows of the dataset
diabetes_dataset.head(10)

# number of rows and columns in this dataset
diabetes_dataset.shape

# getting the statistical measures of the data
diabetes_dataset.describe()

#Countng values of outcomes having 0 or 1, 0 means non diabetic and 1 means diabetic
sns.countplot(x='Outcome',data=diabetes_dataset)

diabetes_dataset['Outcome'].value_counts()

diabetes_dataset.groupby('Outcome').mean()

"""**Data** **Cleaning**"""

#Check if any null or empty data is present in dataset
diabetes_dataset.isna().sum()

# separating the data and labels
X = diabetes_dataset.drop(columns = 'Outcome', axis=1)
Y = diabetes_dataset['Outcome']

print(X)

print(Y)

"""**Exploratory** **Data** **Analysis**"""

#glucose for diabetic
fig = plt.figure(figsize =(15,5))

sns.distplot(diabetes_dataset["Glucose"][diabetes_dataset["Outcome"] == 1])
plt.xticks([i for i in range(0,201,15)],rotation = 45)
plt.ylabel("Glucose count")
plt.title("Glucose",fontsize = 25)

#insulin for diabetic 

fig = plt.figure(figsize = (15,5))

sns.distplot(diabetes_dataset["Insulin"][diabetes_dataset["Outcome"]==1])
plt.xticks()
plt.title("Insulin",fontsize = 25)

#BMI for diabetic
fig = plt.figure(figsize =(15,5))

sns.distplot(diabetes_dataset["BMI"][diabetes_dataset["Outcome"]==1])
plt.xticks()
plt.title("BMI",fontsize = 25)

#diabeticpedigreefunction for diabetic
fig = plt.figure(figsize = (15,6))
sns.distplot(diabetes_dataset["DiabetesPedigreeFunction"][diabetes_dataset["Outcome"] == 1])
plt.xticks([i*0.15 for i in range(1,12)])
plt.title("diabetespedigreefunction")

#Age for diabetic
fig = plt.figure(figsize = (15,5))

sns.distplot(diabetes_dataset["Age"][diabetes_dataset["Outcome"] == 1])
plt.xticks([i*0.15 for i in range(1,12)])
plt.title("Age")

#Removing unnessary columns
X = diabetes_dataset.drop(["Pregnancies","BloodPressure","SkinThickness","Outcome"],axis = 1)
Y = diabetes_dataset.iloc[:,-1]

"""**Data** **Standardization**"""

scaler = StandardScaler()
scaler.fit(X)
standardized_data = scaler.transform(X)
print(standardized_data)

X = standardized_data
Y = diabetes_dataset['Outcome']
print(X)
print(Y)

"""**Train** **Test** **Split**"""

X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, stratify=Y, random_state=2)
print(X.shape, X_train.shape, X_test.shape)

"""**Model** **Building** - **K** **Nearset** **Neighbor**"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors =25, metric = 'minkowski') 
#n_neighbors is 25 bcoz for x_train we got 614 which is near to 25^2
#metric means on what factor choosing so as its KNN so our metric is minkowski i.e., distance
knn.fit(X_train, Y_train)

#Predicting the data
knn_Y_pred = knn.predict(X_test)

knn_Y_pred

# Confusion matrix - To check how many are correct or wrong 
from sklearn.metrics import confusion_matrix
knn_cm = confusion_matrix(Y_test, knn_Y_pred)
sns.heatmap(knn_cm, annot=True)

#Verfying accuracy using inbuilt methods
from sklearn.metrics import accuracy_score
accuracy_score(Y_test,knn_Y_pred)

"""**Simple** **Vector** **Machine**"""

from sklearn.svm import SVC
svc=SVC(kernel="linear")
svc.fit(X_train,Y_train)

svc_Y_pred = svc.predict(X_test)

print("Correct:",sum(svc_Y_pred == Y_test))
print("Incorrect : ",sum(svc_Y_pred != Y_test))
print("Accuracy:",sum(svc_Y_pred ==Y_test)/len(knn_Y_pred))

"""**Saving** **The** **Classifier**"""

import pickle
pickle.dump(svc, open('classifier.pkl', 'wb'))

pickle.dump(scaler, open('scaler.pkl', 'wb'))